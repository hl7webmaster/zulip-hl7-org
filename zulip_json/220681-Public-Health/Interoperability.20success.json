[
    {
        "content": "<p>The Public Health WG is having a discussion on how to measure the success of interoperability incentive programs (spurred on by a HIMSS blog post (<a href=\"https://www.himss.org/resources/determining-measures-success-interoperability\" target=\"_blank\" title=\"https://www.himss.org/resources/determining-measures-success-interoperability\">https://www.himss.org/resources/determining-measures-success-interoperability</a>)). We’ve set aside some time on the Jan 24th call to further talk about the topic. All are welcome to join.</p>",
        "id": 186104140,
        "sender_full_name": "Craig Newman",
        "timestamp": 1579528911
    },
    {
        "content": "<p>Points to consider for possible feedback to HIMSS:<br>\n• Any assessment of overall interoperability success should include the impact on population health (public health) in addition to the benefits for providers and patients<br>\n• Measures should consider both the quantity of messages and the quality of messages<br>\n○ Just increasing the number of messages flowing will not be sufficient for maximal impact<br>\n§ More messages may not equate to improved experience if it means that more fragmented data is available and requiring reconciliation<br>\n§ More complex patterns of data flow (eg. from a provider to an HIE and then on to a public health agency) may complicate data analysis<br>\n□ Should a multi-hop exchange count as just a single exchange of data or multiple?<br>\n§ Many submitters to public health are still using batch submissions which are still valuable (albeit perhaps not as valuable as real time exchange) but harder to assess<br>\n○ The quality of the data is just as (or more) important<br>\n§ Quality can include accuracy, timeliness, completeness and standardization<br>\n§ Measuring the adoption of standard terminologies could be one way to assess improved quality<br>\n§ Proportion of discrete data (coded test results rather than a textual narrative, discrete name components, etc) may also be a useful metric<br>\n• A reduction in cost and time to onboard submitters is also a potential metric (with the ability to measure real world impact on public health programs)<br>\n• Other reductions in cost are also good indicators of success<br>\n○ Does it require fewer resources to data cleanse, deduplicate data, etc?<br>\n• Even with public health, there may be significant variation between programs<br>\n○ For example, electronic immunization reporting was well established prior to incentive programs but still saw a marked increase in data exchange while electronic case reporting has only developed recently and is not as widely implemented (but getting off the ground is often the hardest part)<br>\n• Ultimately, it is the impact on patients, providers and public health programs which should be the true measure of interoperability success<br>\n• Some assessment work is already happening in the public health space<br>\n○ Societies such as the American Immunization Registry Association (AIRA) may already be capturing data<br>\n○ Individual jurisdictions are already looking at assessing data quality in submitted data</p>",
        "id": 186104267,
        "sender_full_name": "Craig Newman",
        "timestamp": 1579528994
    }
]